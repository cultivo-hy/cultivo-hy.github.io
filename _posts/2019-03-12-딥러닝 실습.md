---
layout: post

title: "[딥러닝] 국가건강검진 데이터를 활용한 당뇨병/고혈압 예측"

tags:

- deep learning
- python
- tensorflow

category:
- deep learning
- python
- tensorflow

---
* toc
{:toc}

# [딥러닝] 딥러닝 실습

![1552370311347](https://user-images.githubusercontent.com/23732754/54178151-28399d80-44d8-11e9-8438-1f70586544f0.png)

![1552370447146](https://user-images.githubusercontent.com/23732754/54178037-b3666380-44d7-11e9-9733-31a847401e79.png)

![1552370571695](C:\Users\dwhyl\AppData\Roaming\Typora\typora-user-images\1552370571695.png)



```
import tensorflow as tf
import numpy as np
import os
import time
import matplotlib.pyplot as plt

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
tf.set_random_seed(777)   # for reproducibility
nb_classes = 4

def read(input):
    data = np.loadtxt(input, delimiter=',', dtype=np.float32)
    data = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))
    x_data = data[:, 0:-1]
    y_data = data[:, [-1]]
    return x_data, y_data

def layer():
    X = tf.placeholder(tf.float32, [None, 5])
    Y = tf.placeholder(tf.int32, [None, 1])

    W1 = tf.get_variable("weight1", shape=[5, 10], initializer=tf.contrib.layers.xavier_initializer())
    b1 = tf.Variable(tf.random_normal([10]), name='bias1')
    layer1 =  tf.nn.tanh(tf.matmul(X, W1) + b1)

    W2 = tf.get_variable("weight2", shape=[10, 10], initializer=tf.contrib.layers.xavier_initializer())
    b2 = tf.Variable(tf.random_normal([10]), name='bias2')
    layer2 = tf.nn.tanh(tf.matmul(layer1, W2) + b2)

    W3 = tf.get_variable("weight3", shape=[10, 10], initializer=tf.contrib.layers.xavier_initializer())
    b3 = tf.Variable(tf.random_normal([10]), name='bias3')
    layer3 = tf.nn.tanh(tf.matmul(layer2,W3) + b3)

    W4 = tf.get_variable("weight4", shape=[10, 10], initializer=tf.contrib.layers.xavier_initializer())
    b4 = tf.Variable(tf.random_normal([10]), name='bias4')
    layer4 = tf.nn.tanh(tf.matmul(layer3,W4) + b4)

    W5 = tf.get_variable("weight5", shape=[10, nb_classes], initializer=tf.contrib.layers.xavier_initializer())
    b5 = tf.Variable(tf.random_normal([nb_classes]), name='bias5')
    hypothesis = tf.nn.softmax(tf.matmul(layer4,W5) + b5)

    return X, Y, hypothesis

def cost(Y_one_hot, hypothesis):
    cost_op = tf.reduce_mean(-tf.reduce_sum(Y_one_hot * tf.log(hypothesis), axis =1))
    return cost_op

def trainning(loss_op, learning_rate):
    optimizer = tf.train.AdamOptimizer(learning_rate)
    train_op = optimizer.minimize(loss_op)
    return train_op

def evaluation(Y_one_hot, hypothesis):
    prediction = tf.argmax(hypothesis, 1)
    corrected_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))
    accuracy = tf.reduce_mean(tf.cast(corrected_prediction, tf.float32))
    return accuracy

if __name__ == "__main__":
    start_time = time.time()
    input, output = read('learning_data.csv')
    testInput, testOutput = read('test_data.csv')

    X, Y, logits = layer()
    Y_one_hot = tf.reshape(tf.one_hot(Y, nb_classes), [-1, nb_classes])  # reshape 해준다
    cost_op = cost(Y_one_hot,logits)
    train = trainning(cost_op, 0.3)
    acc = evaluation(Y_one_hot, logits)
    lcost, lcost2, lacc= [], [], []
    xindex= []
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for step in range(1000):
            cost, acc_learn, _ = sess.run([cost_op, acc, train] , feed_dict={X: input, Y: output})
            cost2 = sess.run(cost_op, feed_dict = {X : testInput, Y:testOutput})
            lcost.append(cost)
            lacc.append(acc_learn)
            print("Step: {:5d} \tcost: {:.5f} \tAcc_learn: {:.5f}%".format(step + 1, cost, acc_learn * 100))
            xindex.append(step)
        acc_test = sess.run(acc, feed_dict={X: testInput, Y: testOutput })
        print("Acc_test: {:.5f}%".format(acc_test * 100))
        print("--- %s seconds ---" % (time.time() - start_time))
    plt.plot(xindex,lacc, 'red', label = 'acc_learn')
    plt.ylim(0,1)
    plt.ylabel('acc_learn')
    plt.show()

    plt.plot(xindex,lcost,'blue', label = 'cost')
    plt.ylim(0, 3)
    plt.ylabel('cost')
    plt.show()
```

